# DATA INTEGRATION
## Data Task Description

In this project I will learn about building data pipeline using python to integrate data from multiple sources. We have 3 sources data, saved in: PosgresSQL, API and Gsheet. Data Scientist/Data Analyst might need these data to be organized in one single storage thatâ€™s immediately suitable for analysis. So, Building Data Pipeline to Extract, Transfrom and Load it to one single Data Warehouse would be appropriate solution for it. Therefore, we need to build Pipeline from data source to data warehouse. We also will ingest data from the Data Warehouse and use the data for Machine Learning Modeling, then predict the data using Machine Learning model, and dump the model into MinIO. All process in this data integration will be saved in log database.

## Data Pipeline Design

## Result 

To run this Docker Compose, using this command

```
docker compose up -d
```
